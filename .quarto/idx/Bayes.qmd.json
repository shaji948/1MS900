{"title":"Bayesian Statistics","markdown":{"yaml":{"title":"Bayesian Statistics","format":"html","editor":"visual"},"headingText":"Computational Techniques","containsRefs":false,"markdown":"\n\n## Approximating Posterior Moments\n### Independent Monte Carlo\n\n```{r}\n#### Independent Monte Carlo ####\n## Data\nn <- 20\nsumy <- 40.4\nsumysq <- 93.2\nR <- 5e03\n## Posterior \nbetan <- sumy / (n + 1)\nan <- 2 + n / 2\nbn <- 2 + 0.5 * (sumysq - ((sumy ^ 2)) / (n + 1))\n## Independent Monte Carlo\nset.seed(12345)\nsigma.sq <- rep(NA, R)\nbeta <- rep(NA, R)\nfor(r in 1 : R){\n    sigma.sq[r] <- 1 / rgamma(n = 1, shape = an, rate = bn)\n    beta[r] <- rnorm(n = 1, mean = betan, sd = sqrt(sigma.sq[r] / (n + 1)))\n}\n## Plot the results\npar(mar = c(4.1, 4.1, 1.5, 1))\nplot(cumsum(beta) / (1 : R), type = \"l\", xlab = \"n\", ylab = \"Independent Monte Carlo approximation\")\nabline(h = sumy / (n + 1), col = 2, lty = 2, lwd = 2)\n```\n\n### Importance Sampling\n```{r}\n#### Importance Sampling ####\n## Data\nn <- 20\nsumy <- 40.4\nybar <- sumy / 20\nsumysq <- 93.2\nysd <- sqrt((sumysq - n * ybar ^ 2) / (n - 1))\n## Posterior \nbetan <- sumy / (n + 1)\nan <- 2 + n / 2\nbn <- 2 + 0.5 * (sumysq - ((sumy ^ 2)) / (n + 1))\n## Density of inverse-Gamma distribution\nIvGamma <- function(x, a, b){\n    exp(a * log(b) - lgamma(a) - (a + 1) * log(x) - b / x)\n} \n## Monte Carlo\nset.seed(123456)\nR <- 5e03\nh.pi.g <- rep(NA, R)\nfor(r in 1 : R){\n    ## We use Exp(1 / ybar) as the importance distribution\n    proposal <- rexp(n = 1, rate = 1 / ybar)\n    ## Compute the value of h(theta) * pi(theta | data) / g(theta)\n    h.pi.g[r] <- proposal * IvGamma(proposal, an, bn) / dexp(proposal, rate = 1 / ybar)\n}\n## Plot the results\npar(mar = c(4.1, 4.1, 1.5, 1))\nplot(cumsum(h.pi.g) / (1 : R), type = \"l\", xlab = \"n\", ylab = \"Importance Sampling\")\nabline(h = bn / (an - 1), col = 2, lty = 2, lwd = 2)\n```\n\n\n### Normalized Importance Sampling\n```{r}\n#### Normalized Importance Sampling ####\nset.seed(123456)\nw <- rep(NA, R)\nNIS <- rep(NA, R)\nfor(r in 1 : R){\n    ## Simulate sigma and beta\n    sigma.sq <- rexp(n = 1, rate = 1 / ybar)\n    beta <- rnorm(n = 1, mean = ybar, sd = ysd)\n    ## Compute the densities\n    posterior <- exp(-0.5 * ((n + 1) * beta ^ 2 - 2 * beta * sumy + 4 + sumysq) / sigma.sq) / (sigma.sq ^ (0.5 * (n + 1) + 3))\n    g.density <- dnorm(x = beta, mean = ybar, sd = ysd) * dexp(x = sigma.sq, rate = 1 / ybar)\n    ## normalized IS estimator\n    w[r] <- posterior / g.density\n    NIS[r] <- w[r] * sigma.sq\n}\n## Plot the results\npar(mar = c(4.1, 4.1, 1.5, 1))\nplot(cumsum(NIS) / cumsum(w), type = \"l\", xlab = \"n\", ylab = \"Normalized Importance Sampling\")\nabline(h = bn / (an - 1), col = 2, lty = 2, lwd = 2)\n```\n\n\n## Sampling from Posterior Distribution\n### Metropolis-Hastings Algorithm\n```{r}\n#### Metropolis-Hastings Algorithm ####\n## Data\nn <- 20\nsumy <- 40.4\nsumysq <- 93.2\nybar <- sumy / n\nysd <- sqrt((sumysq - n * ybar ^ 2) / (n - 1))\n## Define function for posterior density\nposterior <- function(beta, sigma.sq) {\n    exp(-0.5 * ((n + 1) * beta ^ 2 - 2 * beta * sumy + 4 + sumysq) / sigma.sq) / \n        (sigma.sq ^ (0.5 * (n + 1) + 3))\n}\n## Define function for Metropolis-Hastings algorithm\nMHalgorithm <- function(L, initial, sd) {   \n    # L is the length of the Markov chain, including the burn-in period\n    # initial is the initial state\n    # sd is the standard deviation of the proposal distribution for beta\n    chain <- rbind(c(initial), matrix(NA, L, length(initial)))\n    for(t in 1 : L){\n        # Propose a candidate\n        beta.prop <- rnorm(n = 1, mean = chain[t, 1], sd = sd)\n        sigmasq.prop <- rexp(n = 1, rate = 1 / chain[t, 2])\n        # Calculate the ratio\n        numerator <- posterior(beta = beta.prop, sigma.sq = sigmasq.prop) * \n            dnorm(x = chain[t, 1], mean = beta.prop, sd = sd) * \n            dexp(x = chain[t, 2], rate = 1 / sigmasq.prop)\n        denominator <- posterior(beta = chain[t, 1], sigma.sq = chain[t, 2]) * \n            dnorm(x = beta.prop, mean = chain[t, 1], sd = sd) * \n            dexp(x = sigmasq.prop, rate = 1 / chain[t, 2])\n        r <- numerator / denominator\n        # Generate U(0, 1)\n        u <- runif(1, 0, 1)\n        # Update\n        if(u <= r) {     \n            chain[t + 1, ] <- c(beta.prop, sigmasq.prop)\n        } else {     \n            chain[t + 1, ] <- chain[t, ]       \n        }\n    }\n    chain\n}\n## Perform MCMC sampling\nset.seed(12345)\nMH <- MHalgorithm(L = 20000, initial = c(0, 1), sd = 0.2) # sd is a tuning parameter\npar(mfrow = c(2, 1), mar = c(4.1, 4.1, 1.5, 1)) \nplot(MH[, 1], type = \"l\", ylab = expression(beta))  \nplot(MH[, 2], type = \"l\", ylab = expression(sigma^2))\n```\n\n\n### Gibbs Sampler\n```{r}\n#### Gibbs Sampler ####\n## Generate some fake data\nset.seed(12345)\nMu <- rnorm(1, 0, 2) \nLambda <- rexp(1, rate = 2) \nData <- rnorm(500, mean = Mu, sd = 1 / sqrt(Lambda)) \n## Define function for Gibbs sampler\nGibbs <- function(L, initial, data, mu0, lam0, b0){    \n    # L is the length of the Markov chain, including the burn-in period\n    # initial is the initial state\n    # data is our data\n    # mu0, lam0 and b0 are the hyperparameters\n    \n    ## Information from data\n    n <- length(data)     \n    s <- sum(data)     \n    s2 <- sum(data ^ 2)   \n    ## Initiate mu and lambda\n    mu <- numeric(1 + L)     \n    mu[1] <- initial[1]     \n    lambda <- numeric(1 + L)  \n    lambda[1] <- initial[2] \n    ## Run MCMC in a for loop\n    for(t in 2 : (1 + L)){         \n        ## Generate mu given lambda\n        mean_norm <- (s / lam0 + mu0 / lambda[t - 1]) / (n / lam0 + 1 / lambda[t - 1])         \n        sd_norm <- 1 / sqrt(lambda[t - 1] * lam0 * (n / lam0 + 1 / lambda[t - 1]))         \n        mu[t] <- rnorm(n = 1, mean = mean_norm, sd = sd_norm)  \n        ## Generate lambda given mu\n        lambda[t] <- rgamma(n = 1, shape = n / 2 + 1, \n                            rate = b0 + 0.5 * (s2 - 2 * mu[t] * s + n * mu[t] ^ 2))     \n    }     \n    ## Return the chain \n    chain <- cbind(mu, lambda)     \n    colnames(chain) <- c(\"mu\", \"lambda\")     \n    return(chain) \n} \n## Run Gibbs sampler\nset.seed(123456) \nGibbsEx <- Gibbs(L = 10000, initial = c(0, 1), data = Data, mu0 = 1, lam0 = 1, b0 = 1) \n## Plot results\npar(mfrow = c(2, 1), mar = c(4.1, 4.1, 1, 1)) \nplot(GibbsEx[, \"mu\"], type = \"l\", ylab = expression(mu)) \nplot(GibbsEx[, \"lambda\"], type = \"l\", ylab = expression(lambda)) \n```\n\n### Hamitonian MC\n```{r}\n#### Hamiltonian MC ####\n## log posterior density and its gradient\nlogpi <- function(beta, sigma.sq, n, sumy, sumysq) {\n    -0.5 * ((n + 1) * beta ^ 2 - 2 * beta * sumy + 4 + sumysq) / sigma.sq - (0.5 * (n + 1) + 3) * log(sigma.sq)\n}\ngrad_logpi <- function(beta, sigma.sq, n, sumy, sumysq){\n    der_beta <- -((n + 1) * beta - sumy) / sigma.sq\n    der_sigma2 <- 0.5 * ((n + 1) * beta ^ 2 - 2 * beta * sumy + 4 + sumysq) / (sigma.sq ^ 2) - (0.5 * (n + 1) + 3) / sigma.sq\n    return(matrix(c(der_beta, der_sigma2), nrow = 2, ncol = 1))\n}\nf <- function(x) logpi(beta = x[1], sigma.sq = x[2], n = 20, sumy = 40.4, sumysq = 93.2)\nnumDeriv::grad(func = f, x = c(0.1, 0.3))\ngrad_logpi(beta = 0.1, sigma.sq = 0.3, n = 20, sumy = 40.4, sumysq = 93.2)\n\n## Define function for HMC\nHMC <- function(n, x0, n.obs, sumy, sumysq, logpi, grad_logpi, sd_phi, epsilon, L) {     \n    # n is the length of the Markov chain, including burn-in period     \n    # x0 is the initial state\n    # n.obs is the number of observations\n    # logpi is the function to calculate the posterior\n    # grad_logpi is the function to calculate the gradient of the posterior\n    # sd_phi is the vector of standard deviation used to generate the momentum from a normal distribution with zero mean\n    # epsilon is the step size in Leapfrog method\n    # L is the number of steps in Leapfrog method\n    \n    ## Initiate the Markov chain\n    chain <- rbind(x0, matrix(NA, n, 2))     \n    ## Generate random number using HMC in a for loop\n    for(t in 1 : n){         \n        ## Draw momentum from normal         \n        phi0 <- c(rnorm(1, mean = 0, sd = sd_phi[1]), rnorm(1, mean = 0, sd = sd_phi[2]))     \n        #-------------------------------------#         \n        # Leapfrog to update x         \n        x <- chain[t, ]         \n        # Current Hamiltonian         \n        H <- -logpi(beta = x[1], sigma.sq = x[2], n = n.obs, sumy, sumysq) - dnorm(phi0[1], mean = 0, sd = sd_phi[1], log = TRUE) - dnorm(phi0[2], mean = 0, sd = sd_phi[2], log = TRUE)         \n        # Make a half step for momentum at the beginning         \n        phi <- phi0 + epsilon * grad_logpi(beta = x[1], sigma.sq = x[2], n = n.obs, sumy, sumysq) / 2        \n        # Alternate full steps for position and momentum         \n        for (i in 1 : L){             \n            # Make a full step for the position             \n            x <- x + epsilon * diag(1 / sd_phi, 2) %*% phi             \n            # Make a full step for the momentum, except at end of trajectory             \n            if (i != L) {                 \n                phi <- phi + epsilon * grad_logpi(beta = x[1], sigma.sq = x[2], n = n.obs, sumy, sumysq)            \n            }         \n        }         \n        # Make a half step for momentum at the end.         \n        phi <- phi + epsilon * grad_logpi(beta = x[1], sigma.sq = x[2], n = n.obs, sumy, sumysq) / 2         \n        #-------------------------------------#         \n        # Negate momentum at end of trajectory to make the proposal symmetric         \n        phistar <- -phi         \n        # Proposed Hamiltonian         \n        Hstar <- -logpi(beta = x[1], sigma.sq = x[2], n = n.obs, sumy, sumysq) - dnorm(phistar[1], mean = 0, sd = sd_phi[1], log = TRUE) - dnorm(phistar[2], mean = 0, sd = sd_phi[2], log = TRUE)               \n        # Metropolis ratio         \n        ratio <- exp(H - Hstar)         \n        # Accept or reject the state at end of trajectory, returning either         \n        # the position at the end of the trajectory or the initial position         \n        if (runif(1) < ratio){             \n            chain[t + 1, ] <- x         \n        } else {             \n            chain[t + 1, ] <- chain[t, ]          \n        }     \n    }     \n    return(chain)\n}\n## Run HMC\nset.seed(12345)\nHMCdraw <- HMC(n = 10000, x0 = c(0, 0.6), n.obs = 20, sumy = 40.4, sumysq = 93.2,\n               logpi = logpi, grad_logpi = grad_logpi,                 \n               sd_phi = c(1.5, 1.5), epsilon = 0.05, L = 20) \n## Plot results\npar(mfrow = c(2, 1), mar = c(4.1, 4.1, 1, 1)) \nplot(HMCdraw[-c(1 : 5000), 1], type = \"l\")  \nplot(HMCdraw[-c(1 : 5000), 2], type = \"l\") \n```\n\n\n## Rao-Blackwellization\n```{r}\n## Our data\n## Generate some fake data\nset.seed(12345)\nMu <- rnorm(1, 0, 2) \nLambda <- rexp(1, rate = 2) \nN <- 500\nData <- rnorm(N, mean = Mu, sd = 1 / sqrt(Lambda)) \n## Define function for Gibbs sampler\nGibbs <- function(L, initial, data, mu0, lam0, a0, b0){    \n    # L is the length of the Markov chain, including the burn-in period\n    # initial is the initial state\n    # data is our data\n    # mu0, lam0, a0, and b0 are the hyperparameters\n    \n    ## Information from data\n    n <- length(data)     \n    sumx <- sum(data)     \n    sumx2 <- sum(data ^ 2)   \n    ## Initiate mu and lambda\n    mu <- numeric(1 + L)     \n    mu[1] <- initial[1]     \n    lambda <- numeric(1 + L)  \n    lambda[1] <- initial[2] \n    ## Run MCMC in a for loop\n    for(t in 2 : (1 + L)){       \n        ## Generate mu given lambda\n        normal.mean <- (lam0 * mu0 + lambda[t - 1] * sumx) / (lam0 + n * lambda[t - 1])\n        normal.var <- lam0 + n * lambda[t - 1]\n        mu[t] <- rnorm(1, normal.mean, 1 / sqrt(normal.var)) \n        ## Generate lambda given mu\n        bn <- b0 + 0.5 * sumx2 - sumx * mu[5] + 0.5 * n * mu[5]^2       \n        lambda[t] <- rgamma(n = 1, shape = a0 + n / 2, rate = bn)     \n    }     \n    ## Return the chain \n    chain <- cbind(mu, lambda)     \n    colnames(chain) <- c(\"mu\", \"lambda\")     \n    return(chain) \n} \n## Run Gibbs sampler multiple times\na0 <- 1\nb0 <- 1\nRep <- 1e03 \nNaive <- RB <- numeric(Rep) \nfor(r in 1 : Rep){     \n    MuLambda <- Gibbs(L = 1000, initial = c(0, 1), data = Data, mu0 = 1, lam0 = 1, a0 = a0, b0 = b0)\n    ## Discard burn-in period\n    MuLambda <- MuLambda[-c(1 : 500), ]\n    ## Naive MC     \n    Naive[r] <- mean(MuLambda[, 2])     \n    ## Rao-Blackwell     \n    Bn <- b0 + 0.5 * sum(Data ^ 2)  - sum(Data) * MuLambda[, 1] + 0.5 * N * (MuLambda[, 1] ^ 2)\n    RB[r] <- mean((a0 + N / 2) / Bn) \n} \n## Compare results with and without Rao-Blackwell\nmean(Naive); var(Naive) \nmean(RB); var(RB)\n```\n\n## Stan\n```{r, echo = FALSE, eval = TRUE}\nload(\"C:/Users/shaji948/Box/Teaching/Math Department/Bayesian Statistics 1MS900/R/Bernoulli.RData\")\n```\n\nSuppose that $X_{i}\\mid\\theta\\sim\\text{Bernoulli}\\left(\\theta\\right)$ and $\\theta\\sim\\text{Beta}\\left(a_{0},b_{0}\\right)$. We load data\n```{r, echo = TRUE, eval = FALSE}\nload(\"Bernoulli.RData\")\n```\n\n\n```{r, message = FALSE, warning = FALSE}\n## Step 1: create Stan program \n#### It has three blocks: data, parameters, model \nbetabinomial =  \" \ndata {   \n   int<lower=0> N ; // Number of Bernoulli variables   \n   int<lower=0, upper=1> y[N] ; // integer valued y of length N  \n}\nparameters {   \n   real<lower=0, upper=1> theta ; // success probability \n}\nmodel {   \n   theta ~ uniform(0, 1) ; // prior   \n   y ~ bernoulli(theta) ; // likelihood \n} \n\"\n\n## Step 2: Posterior simulation using Stan \n## It takes time the first time, because the code needs to be compiled first.  \nlibrary(rstan) \nNUTS <- stan(model_code = betabinomial, data = list(y = Success, N = 20),              \n            iter = 5000, # the length of each Markov chain, including warmup             \n            warmup = 5000 / 2, # default is 50% is burn-in              \n            thin = 1, # 1 means that no thining is done\n            chains = 4)\n```\n\nWe can extract information from `NUTS` using\n```{r}\nRes <- extract(NUTS, permuted = FALSE)\n```\nTo extract the posterior draws, we use\n```{r}\nPostDraw <- Res[, , \"theta\"] \n```\n\nTraceplot to check convergence visually\n```{r}\ntraceplot(NUTS) \n```\nOther summary statistics are\n```{r}\n## Rhat: < 1.01\nRhat(PostDraw) \n## Effective sample size\nsummary(NUTS)$summary[, \"n_eff\"] \n## Number of divergent transitions\n## It occurs if curvature of posterior is large such that it is difficult to explore\nget_num_divergent(NUTS) # Should vanish if control = list(adapt_delta) goes to 1\n```\nIn fact, you get many summaries from \n```{r}\nprint(NUTS)\n```\n\nIf we let permuted = TRUE, then we have a vector. Each chain has length 5000 where 2500 will be discarded as burn.in. We have in total 4 chains, then there will be 4 * 2500 left. \n```{r}\nPostDraw <- extract(NUTS, permuted = TRUE)$theta \n```\n\nTo make posterior inference. we can use `PostDraw` directly.\n```{r}\n## Posterior mean\nmean(PostDraw)\n## Credible set\nquantile(PostDraw, probs = c(0.025, 0.975)) \n```\n\n\n## Regression Using Stan in R\nLoad package for regression\n```{r, message = FALSE, warning = FALSE}\nlibrary(rstanarm) \n```\nRead data\n```{r}\ndata(penguins, package = \"palmerpenguins\")  \nhead(penguins)  \npenguins <- na.omit(penguins)\n```\n\nTo fit the normal linear model\n```{r}\nFit <- stan_glm(bill_length_mm ~ flipper_length_mm + body_mass_g, # our model                 \n                family = gaussian(), # distribution of response                 \n                data = penguins) \n```\n\nWe can check the default prior. Note that the package does some internal adjustment to the specified prior. \n```{r}\nprior_summary(Fit)\n```\n \nIf we want to specify the priors ourselves, it is possible to do so, but not very flexible. For example, if we let autoscale = FALSE, we can switch off the internal adjustment.\n```{r}\nFit <- stan_glm(bill_length_mm ~ flipper_length_mm + body_mass_g, # our model                 \n                family = gaussian(), # distribution of response                 \n                prior = normal(location = c(0, 0), scale = c(2.5, 2.5), autoscale = FALSE),                 \n                prior_aux = exponential(rate = 1, autoscale = FALSE), # Prior for sigma    \n                data = penguins) \n```\n\nHowever, the prior is set on $\\sigma$, not $\\sigma^{2}$. Hence, it is not really possible to use the inverse gamma prior. Further, as the Jeffreys-Lindley Paradox, we cannot use a proper prior to approximate an improper prior. The package only uses the independent prior for the regression coefficients.\n\nSuppose that we want to tune the above code. I want to change the prior, change the number of chains, and the length.\n```{r}\nFit <- stan_glm(bill_length_mm ~ flipper_length_mm + body_mass_g, # our model                 \n                family = gaussian(), # distribution of response                 \n                prior = student_t(df = 3, location = c(0, 0), scale = c(2.5, 2.5), \n                                  autoscale = FALSE),            \n                prior_aux = exponential(rate = 1, autoscale = FALSE), # Prior for sigma           \n                chains = 4, iter = 1e04, warmup = 1e04 / 2, # Pass to rstan\n                data = penguins) \n```\n\n\nAfter fitting the model, we can extract information from the Markov chains.\n```{r}\n## Point estimate of coefficients\ncoef(Fit) # Posterior median, not mean\n## Posterior Credible interval\nposterior_interval(Fit, prob = 0.95)\n## Posterior prediction for each draw after burn-in period \nPredict <- posterior_predict(Fit, newdata = penguins[1 : 5, ])\n```\nWe can also extract posterior draws.\n```{r, echo = TRUE, eval = FALSE}\n## Posterior draws from the Markov chain\nas.matrix(Fit)\n```\n\nYou can conduct posterior predictive check easily.\n```{r}\npp_check(Fit) # We can use pp_check(Fit, nreps = 10) to change the replications.\n```\n\nIf we want to do prior predictive check, we use prior_PD = TRUE, then the predictions are only drawn from the prior without using the data\n```{r}\nFit <- stan_glm(bill_length_mm ~ flipper_length_mm + body_mass_g, # our model                 \n                family = gaussian(), # distribution of response                 \n                prior = student_t(df = 3, location = c(0, 0), scale = c(2.5, 2.5), \n                                  autoscale = FALSE),            \n                prior_aux = exponential(rate = 1, autoscale = FALSE), # Prior for sigma           \n                prior_PD = TRUE, # prior predictive check\n                data = penguins) \npp_check(Fit)\n```\nThis is “bad” prior, because predicted Y can be negative quite frequently.\n```{r}\nrange(posterior_predict(Fit))\n```\n\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"number-sections":true,"output-file":"Bayes.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","theme":"cosmo","title":"Bayesian Statistics","editor":"visual"},"extensions":{"book":{"multiFile":true}}}}}