---
title: "Bayesian Statistics"
format: html
editor: visual
---

# Computational Techniques
## Approximating Posterior Moments
### Independent Monte Carlo

```{r}
#### Independent Monte Carlo ####
## Data
n <- 20
sumy <- 40.4
sumysq <- 93.2
R <- 5e03
## Posterior 
betan <- sumy / (n + 1)
an <- 2 + n / 2
bn <- 2 + 0.5 * (sumysq - ((sumy ^ 2)) / (n + 1))
## Independent Monte Carlo
set.seed(12345)
sigma.sq <- rep(NA, R)
beta <- rep(NA, R)
for(r in 1 : R){
    sigma.sq[r] <- 1 / rgamma(n = 1, shape = an, rate = bn)
    beta[r] <- rnorm(n = 1, mean = betan, sd = sqrt(sigma.sq[r] / (n + 1)))
}
## Plot the results
par(mar = c(4.1, 4.1, 1.5, 1))
plot(cumsum(beta) / (1 : R), type = "l", xlab = "n", ylab = "Independent Monte Carlo approximation")
abline(h = sumy / (n + 1), col = 2, lty = 2, lwd = 2)
```

### Importance Sampling
```{r}
#### Importance Sampling ####
## Data
n <- 20
sumy <- 40.4
ybar <- sumy / 20
sumysq <- 93.2
ysd <- sqrt((sumysq - n * ybar ^ 2) / (n - 1))
## Posterior 
betan <- sumy / (n + 1)
an <- 2 + n / 2
bn <- 2 + 0.5 * (sumysq - ((sumy ^ 2)) / (n + 1))
## Density of inverse-Gamma distribution
IvGamma <- function(x, a, b){
    exp(a * log(b) - lgamma(a) - (a + 1) * log(x) - b / x)
} 
## Monte Carlo
set.seed(123456)
R <- 5e03
h.pi.g <- rep(NA, R)
for(r in 1 : R){
    ## We use Exp(1 / ybar) as the importance distribution
    proposal <- rexp(n = 1, rate = 1 / ybar)
    ## Compute the value of h(theta) * pi(theta | data) / g(theta)
    h.pi.g[r] <- proposal * IvGamma(proposal, an, bn) / dexp(proposal, rate = 1 / ybar)
}
## Plot the results
par(mar = c(4.1, 4.1, 1.5, 1))
plot(cumsum(h.pi.g) / (1 : R), type = "l", xlab = "n", ylab = "Importance Sampling")
abline(h = bn / (an - 1), col = 2, lty = 2, lwd = 2)
```


### Normalized Importance Sampling
```{r}
#### Normalized Importance Sampling ####
set.seed(123456)
w <- rep(NA, R)
NIS <- rep(NA, R)
for(r in 1 : R){
    ## Simulate sigma and beta
    sigma.sq <- rexp(n = 1, rate = 1 / ybar)
    beta <- rnorm(n = 1, mean = ybar, sd = ysd)
    ## Compute the densities
    posterior <- exp(-0.5 * ((n + 1) * beta ^ 2 - 2 * beta * sumy + 4 + sumysq) / sigma.sq) / (sigma.sq ^ (0.5 * (n + 1) + 3))
    g.density <- dnorm(x = beta, mean = ybar, sd = ysd) * dexp(x = sigma.sq, rate = 1 / ybar)
    ## normalized IS estimator
    w[r] <- posterior / g.density
    NIS[r] <- w[r] * sigma.sq
}
## Plot the results
par(mar = c(4.1, 4.1, 1.5, 1))
plot(cumsum(NIS) / cumsum(w), type = "l", xlab = "n", ylab = "Normalized Importance Sampling")
abline(h = bn / (an - 1), col = 2, lty = 2, lwd = 2)
```


## Sampling from Posterior Distribution
### Metropolis-Hastings Algorithm
```{r}
#### Metropolis-Hastings Algorithm ####
## Data
n <- 20
sumy <- 40.4
sumysq <- 93.2
ybar <- sumy / n
ysd <- sqrt((sumysq - n * ybar ^ 2) / (n - 1))
## Define function for posterior density
posterior <- function(beta, sigma.sq) {
    exp(-0.5 * ((n + 1) * beta ^ 2 - 2 * beta * sumy + 4 + sumysq) / sigma.sq) / 
        (sigma.sq ^ (0.5 * (n + 1) + 3))
}
## Define function for Metropolis-Hastings algorithm
MHalgorithm <- function(L, initial, sd) {   
    # L is the length of the Markov chain, including the burn-in period
    # initial is the initial state
    # sd is the standard deviation of the proposal distribution for beta
    chain <- rbind(c(initial), matrix(NA, L, length(initial)))
    for(t in 1 : L){
        # Propose a candidate
        beta.prop <- rnorm(n = 1, mean = chain[t, 1], sd = sd)
        sigmasq.prop <- rexp(n = 1, rate = 1 / chain[t, 2])
        # Calculate the ratio
        numerator <- posterior(beta = beta.prop, sigma.sq = sigmasq.prop) * 
            dnorm(x = chain[t, 1], mean = beta.prop, sd = sd) * 
            dexp(x = chain[t, 2], rate = 1 / sigmasq.prop)
        denominator <- posterior(beta = chain[t, 1], sigma.sq = chain[t, 2]) * 
            dnorm(x = beta.prop, mean = chain[t, 1], sd = sd) * 
            dexp(x = sigmasq.prop, rate = 1 / chain[t, 2])
        r <- numerator / denominator
        # Generate U(0, 1)
        u <- runif(1, 0, 1)
        # Update
        if(u <= r) {     
            chain[t + 1, ] <- c(beta.prop, sigmasq.prop)
        } else {     
            chain[t + 1, ] <- chain[t, ]       
        }
    }
    chain
}
## Perform MCMC sampling
set.seed(12345)
MH <- MHalgorithm(L = 20000, initial = c(0, 1), sd = 0.2) # sd is a tuning parameter
par(mfrow = c(2, 1), mar = c(4.1, 4.1, 1.5, 1)) 
plot(MH[, 1], type = "l", ylab = expression(beta))  
plot(MH[, 2], type = "l", ylab = expression(sigma^2))
```

